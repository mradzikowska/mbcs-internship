{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia notatnika load_hp_fmri_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mradzikowska/mbcs-internship/blob/main/Kopia_notatnika_load_hp_fmri_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhUl2kx7x6Ye"
      },
      "source": [
        "To run this colab, you firs need to upload the harry potter dataset into your google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FijfxKnFYMu"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJjAa0mMIZi2",
        "outputId": "6a18dcc5-2f9a-4490-b5ea-21990c07dafc"
      },
      "source": [
        "#@title Mount google drive (where the data is uploaded).\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImCSjS9VKyWY"
      },
      "source": [
        "subject_id = 'K' #@param \n",
        "subject_data = np.load(f'/content/drive/My Drive/HP_data/fMRI/data_subject_{subject_id}.npy')\n",
        "time_fmri = np.load('/content/drive/My Drive/HP_data/fMRI/time_fmri.npy')\n",
        "runs_fmri = np.load('/content/drive/My Drive/HP_data/fMRI/runs_fmri.npy')\n",
        "words_fmri = np.load('/content/drive/My Drive/HP_data/fMRI/words_fmri.npy')\n",
        "time_words_fmri = np.load('/content/drive/My Drive/HP_data/fMRI/time_words_fmri.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvTkAP2ORHVJ"
      },
      "source": [
        "def delay_one(mat, d):\n",
        "  \"\"\"delays a matrix by a delay d. Positive d ==> row t has row t-d.\"\"\"#Delay is the amount of time in seconds between the time the first of the four word is shown to the subject and when the fMRI scan is started to be taken.\n",
        "  new_mat = np.zeros_like(mat) #Return an array of zeros with the same shape and type as a given array.\n",
        "  if d>0:\n",
        "      new_mat[d:] = mat[:-d]\n",
        "  elif d<0:\n",
        "      new_mat[:d] = mat[-d:]\n",
        "  else:\n",
        "      new_mat = mat\n",
        "  return new_mat\n",
        "\n",
        "def delay_mat(mat, delays):\n",
        "  \"\"\"delays a matrix by a set of delays d.\n",
        "    a row t in the returned matrix has the concatenated:\n",
        "    row(t-delays[0],t-delays[1]...t-delays[last] ).\n",
        "  \"\"\"\n",
        "  new_mat = np.concatenate([delay_one(mat, d) for d in delays],axis = -1)\n",
        "  return new_mat\n",
        "\n",
        "def prepare_nlp_features(train_features, test_features, word_train_indicator, TR_train_indicator, SKIP_WORDS=20, END_WORDS=5176): #we look at the similarities of each of the models with brain representations, only at the steps in the story where an end of a sentence token is reached\n",
        "        \n",
        "    time = np.load('/content/drive/My Drive/HP_data/fMRI/time_fmri.npy')\n",
        "    runs = np.load('/content/drive/My Drive/HP_data/fMRI/runs_fmri.npy') \n",
        "    time_words = np.load('/content/drive/My Drive/HP_data/fMRI/time_words_fmri.npy')\n",
        "    time_words = time_words[SKIP_WORDS:END_WORDS]#?\n",
        "        \n",
        "    words_id = np.zeros([len(time_words)])\n",
        "    # w=find what TR each word belongs to\n",
        "    for i in range(len(time_words)):\n",
        "        words_id[i] = np.where(time_words[i]> time)[0][-1] #condition?\n",
        "        \n",
        "    all_features = np.zeros([time_words.shape[0], train_features.shape[1]])\n",
        "    all_features[word_train_indicator] = train_features\n",
        "    all_features[~word_train_indicator] = test_features\n",
        "        \n",
        "    p = all_features.shape[1]\n",
        "    tmp = np.zeros([time.shape[0], p])\n",
        "    for i in range(time.shape[0]):\n",
        "        tmp[i] = np.mean(all_features[(words_id<=i)*(words_id>i-1)],0)\n",
        "    tmp = delay_mat(tmp, np.arange(1,5))\n",
        "\n",
        "    # remove the edges of each run???\n",
        "    tmp = np.vstack([zscore(tmp[runs==i][20:-15]) for i in range(1,5)])\n",
        "    tmp = np.nan_to_num(tmp)\n",
        "        \n",
        "    return tmp[TR_train_indicator], tmp[~TR_train_indicator]\n",
        "\n",
        "def get_fold_flags(n, n_folds):\n",
        "    flags = np.zeros((n))\n",
        "    num_items_in_each_fold = int(np.floor(n/n_folds))\n",
        "    for i in range(0,n_folds -1):\n",
        "        flags[i*num_items_in_each_fold:(i+1)*num_items_in_each_fold] = i\n",
        "    flags[(n_folds-1)*num_items_in_each_fold:] = (n_folds-1)\n",
        "    return flags\n",
        "    #divides the training set (GT) into K number of parts (folds), then uses one fold at a time as the testing fold and the rest of the data as the training data?\n",
        "\n",
        "def tr_to_word_train_indicator(tr_train_indicator, skip_words=20, end_words=5176):\n",
        "    time = np.load('/content/drive/My Drive/HP_data/fMRI/time_fmri.npy')\n",
        "    runs = np.load('/content/drive/My Drive/HP_data/fMRI/runs_fmri.npy') \n",
        "    time_words = np.load('/content/drive/My Drive/HP_data/fMRI/time_words_fmri.npy')\n",
        "    time_words = time_words[skip_words:end_words]\n",
        "        \n",
        "    word_train_indicator = np.zeros([len(time_words)], dtype=bool)    \n",
        "    words_id = np.zeros([len(time_words)],dtype=int)\n",
        "    # Find what TR each word belongs to.\n",
        "    for i in range(len(time_words)):                \n",
        "        words_id[i] = np.where(time_words[i]> time)[0][-1]\n",
        "        \n",
        "        if words_id[i] <= len(runs) - 15:\n",
        "            offset = runs[int(words_id[i])]*20 + (runs[int(words_id[i])]-1)*15\n",
        "            if tr_train_indicator[int(words_id[i])-offset-1] == 1:\n",
        "                word_train_indicator[i] = True\n",
        "    return word_train_indicator "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GbCOo85SBrY",
        "outputId": "eff14231-57a7-41b7-dd59-bcf3d00025ed"
      },
      "source": [
        "n_words = subject_data.shape[0]\n",
        "n_voxels = subject_data.shape[1]\n",
        "print('Number of voxels for this subject is', n_voxels, 'for', n_words, 'scans.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of voxels for this subject is 25003 for 1211 scans.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Y1GlCcoY9T"
      },
      "source": [
        "n_folds = 4\n",
        "test_fold = 1\n",
        "skip = 5\n",
        "fold_flags = get_fold_flags(n_words, n_folds=n_folds)\n",
        "train_ind = fold_flags!=test_fold\n",
        "test_ind = fold_flags==test_fold\n",
        "train_indicator = tr_to_word_train_indicator(train_ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm9vQZMisj--",
        "outputId": "67ae77d4-b6f6-479d-fb2b-23a717aebc80"
      },
      "source": [
        "#@title Get NLP features (currently it is just a random matrix) DO THIS!!\n",
        "SKIP_WORDS = 20\n",
        "END_WORDS = 5176\n",
        "\n",
        "# You need to replace this with the embeddings that you get from any NLP model for words_fmri.\n",
        "nlp_features = np.random.uniform(size=(len(words_fmri), 100))\n",
        "\n",
        "\n",
        "train_nlp_features = nlp_features[SKIP_WORDS:END_WORDS,:][train_indicator]\n",
        "test_nlp_features = nlp_features[SKIP_WORDS:END_WORDS,:][~train_indicator]\n",
        "train_features, test_features = prepare_nlp_features(train_nlp_features, test_nlp_features, train_indicator, train_ind)\n",
        "\n",
        "print(train_features.shape, test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(909, 400) (302, 400)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "992l0uQYxpEp"
      },
      "source": [
        "#@title Get fmri data points.\n",
        "\n",
        "train_data = subject_data[train_ind]\n",
        "test_data = subject_data[test_ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "q8JR-czTpFG0"
      },
      "source": [
        "#@title Filter out some of data points in the margins of test and train sets.\n",
        "\n",
        "# skip TRs between train and test data\n",
        "if test_fold == 0: # just remove from front end\n",
        "    train_data = train_data[skip:,:]\n",
        "    train_features = train_features[skip:,:]\n",
        "elif test_fold == n_folds-1: # just remove from back end\n",
        "    train_data = train_data[:-skip,:]\n",
        "    train_features = train_features[:-skip,:]\n",
        "else:\n",
        "    test_data = test_data[skip:-skip,:]\n",
        "    test_features = test_features[skip:-skip,:]\n",
        "\n",
        "# normalize data\n",
        "train_data = np.nan_to_num(zscore(np.nan_to_num(train_data)))\n",
        "test_data = np.nan_to_num(zscore(np.nan_to_num(test_data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvFi-uqVqH2L",
        "outputId": "70c2744b-f7ba-4820-92ed-8e7ba945f711"
      },
      "source": [
        "#why is it just to check if it makes sense and first dimensions arethe same?\n",
        "print('fmri features:', train_data.shape, test_data.shape) \n",
        "print('nlp features:', train_features.shape, test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fmri features: (909, 25003) (292, 25003)\n",
            "nlp features: (909, 400) (292, 400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IUN0vbLFcaH"
      },
      "source": [
        "# Representational Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPgeqyk003I2"
      },
      "source": [
        "def dot_product_rsa(reps1, reps2):\n",
        "  \"\"\"Compute representational similarity between two sets of representations.\n",
        "\n",
        "  Args:\n",
        "    reps1: float array; [num_examples, feature_size1]\n",
        "    reps2: float array; [num_examples, feature_size2]\n",
        "  \"\"\"\n",
        "  assert reps1.shape[0] == reps2.shape[0], 'First dimensions of inputs should match.'\n",
        "\n",
        "  # Normalize input representations\n",
        "  reps1 = reps1 / np.linalg.norm(reps1)\n",
        "  reps2 = reps2 / np.linalg.norm(reps2)\n",
        "\n",
        "  # Compute and normalize similarity matrices:\n",
        "  similarities1 = reps1.dot(reps1.T) # instead of dot product you can use any similarity measure #If vectors are identified with row matrices, the dot product can also be written as a matrix product a*b=a*bT\n",
        "  similarities2 = reps2.dot(reps2.T) #dot is relative so has to be standarzied - what about pearson r?\n",
        "  similarities1 = similarities1 / np.linalg.norm(similarities1)\n",
        "  similarities2 = similarities2 / np.linalg.norm(similarities2)\n",
        "\n",
        "  # Here you can do pearson-r instead of this (or again any measure of similarity).\n",
        "  similarity_of_similarity = np.sum(similarities1 * similarities2, axis=-1)\n",
        "  return np.sum(similarity_of_similarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWa2CjELB5fl"
      },
      "source": [
        "def dot_product_rsa_for_lists_of_reps(reps):\n",
        "  \"\"\"Compute representational similarity between two sets of representations.\n",
        "\n",
        "  Args:\n",
        "    reps: list of float arrays; List of arrrays with shape [num_examples, feature_size]\n",
        "      (feature size can be different for each item in the list).\n",
        "  \"\"\"\n",
        "  norm_reps = []\n",
        "  for rep in reps:\n",
        "  # Normalize input representations\n",
        "    norm_reps.append(rep / np.linalg.norm(rep))\n",
        "\n",
        "  # Compute and normalize similarity matrices:\n",
        "  similarity_matrices = []\n",
        "  for rep in norm_reps:\n",
        "    similarities = rep.dot(rep.T) # instead of dot product you can use any similarity measure\n",
        "    similarities = similarities / np.linalg.norm(similarities)\n",
        "    similarity_matrices.append(similarities)\n",
        "\n",
        "  # Shape of similarity_matrices: [num_of_rep_spaces, num_examples, num_examples]\n",
        "  similarity_matrices = np.asarray(similarity_matrices) \n",
        "  sim_of_sim_mat = np.zeros((similarity_matrices.shape[0], \n",
        "                              similarity_matrices.shape[0]))\n",
        "  for i in np.arange(sim_of_sim_mat.shape[0]):\n",
        "    for j in np.arange(sim_of_sim_mat.shape[1]):\n",
        "      # Here you can do pearson-r instead of this (or again any measure of similarity).\n",
        "      similarity_of_similarity = np.sum(\n",
        "          similarity_matrices[i] * similarity_matrices[j], axis=-1)\n",
        "      similarity_score = np.sum(similarity_of_similarity)\n",
        "      sim_of_sim_mat[i][j] = similarity_score\n",
        "  return sim_of_sim_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iOyeZqY1Ox6",
        "outputId": "bdbb75ff-f856-4179-eacf-5015cd11d697"
      },
      "source": [
        "dot_product_rsa(train_data, train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000000000000009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV3KoUZfDmoP",
        "outputId": "3ef55496-bd40-476b-8482-5f466b5f6140"
      },
      "source": [
        "dot_product_rsa_for_lists_of_reps([train_data, train_data])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ROzWo2D1SWB",
        "outputId": "51a9d23e-6628-4239-a847-f892715dcd2f"
      },
      "source": [
        "dot_product_rsa_for_lists_of_reps([train_data, train_features])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.05065051],\n",
              "       [0.05065051, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVsTeJBY3-oB",
        "outputId": "605b2b62-db4a-4722-d588-5c321375f8ea"
      },
      "source": [
        "dot_product_rsa_for_lists_of_reps([train_features, train_features])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTJ69fH14qyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727daf7c-1033-4340-e460-bbf0eda4b811"
      },
      "source": [
        "#@title Compare two subjects:\n",
        "\n",
        "subject_id_1 = 'K' #@param \n",
        "subject_data_1 = np.load(f'/content/drive/My Drive/HP_data/fMRI/data_subject_{subject_id_1}.npy')\n",
        "\n",
        "subject_id_2 = 'F' #@param \n",
        "subject_data_2 = np.load(f'/content/drive/My Drive/HP_data/fMRI/data_subject_{subject_id_2}.npy')\n",
        "\n",
        "subject_data_1 = np.nan_to_num(zscore(np.nan_to_num(subject_data_1)))\n",
        "subject_data_2 = np.nan_to_num(zscore(np.nan_to_num(subject_data_2)))\n",
        "\n",
        "print(f'Representational similarity between subject {subject_id_1} and {subject_id_2} is:', dot_product_rsa(subject_data_1, subject_data_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Representational similarity between subject K and F is: 0.012922335085487204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40yyt-26-Yhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93de82b5-d35b-4dd4-80c8-1e283a926069"
      },
      "source": [
        "subjects = ['K', 'F', 'J', 'M', 'N']\n",
        "subject_data_dict = {}\n",
        "\n",
        "for subject in subjects:\n",
        "  subject_data_dict[subject] = np.load(f'/content/drive/My Drive/HP_data/fMRI/data_subject_{subject}.npy')\n",
        "\n",
        "dot_product_rsa_for_lists_of_reps(subject_data_dict.values())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.01292234, 0.01932876, 0.03175972, 0.01276441],\n",
              "       [0.01292234, 1.        , 0.02822649, 0.07584415, 0.01996322],\n",
              "       [0.01932876, 0.02822649, 1.        , 0.04934054, 0.02140909],\n",
              "       [0.03175972, 0.07584415, 0.04934054, 1.        , 0.03829222],\n",
              "       [0.01276441, 0.01996322, 0.02140909, 0.03829222, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGslbHriEW-Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}