{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "super simple RSA trial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYvBwIwLslncyKUFp24r3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mradzikowska/mbcs-internship/blob/main/super_simple_RSA_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THyEgTCRb_s6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd92fa9d-b869-41a7-ae56-a6acfcd6dc6d"
      },
      "source": [
        "import numpy as np\n",
        "#Create random data\n",
        "data1= np.random.normal(size = 5)\n",
        "data2 = np.random.normal(size = 5)\n",
        "data3 = np.random.normal(size = 5)\n",
        "#Make a data frame\n",
        "import pandas as pd\n",
        "data_1 = pd.DataFrame ({\"a\": data1 ,\n",
        "                      \"b\": data2 ,\n",
        "                      \"c\": data3 })\n",
        "data_1 = data_1.T\n",
        "print(data_1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0         1         2         3         4\n",
            "a  0.392543 -0.911443  0.772151 -0.090814 -1.135782\n",
            "b  1.479959 -0.381182 -0.979437  1.447932 -1.726879\n",
            "c  0.186623  1.185414  0.618395 -0.017583  0.927143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS1bDrbMR8DS",
        "outputId": "14a1a507-d6c7-4509-c7ee-d4267b7e1bea"
      },
      "source": [
        "from scipy.spatial.distance import euclidean, pdist, squareform\n",
        "\n",
        "#compute similarity matrix between each of the rows -- how are columns treated? As one vector? \n",
        "from sklearn.metrics import pairwise_distances #for distance matrix\n",
        "from scipy.spatial.distance import cosine #for cosine similarity\n",
        "\n",
        "dist_matrix_1 = 1-pairwise_distances(data_1, metric=\"cosine\")\n",
        "distance_matrix_1 = pd.DataFrame (dist_matrix_1)\n",
        "print(distance_matrix_1, \"RDM 1\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0         1         2\n",
            "0  1.000000  0.407719 -0.568938\n",
            "1  0.407719  1.000000 -0.508067\n",
            "2 -0.568938 -0.508067  1.000000 RDM 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5xW6eppYwJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b8ce0a-7a6c-43c4-97d7-5e30f833b0a2"
      },
      "source": [
        "#Create second set of data \n",
        "data_a = np.random.randint (low=1,high =20,size =3)\n",
        "data_b = np.random.randint (low = 1, high = 20, size =3)\n",
        "data_c = np.random.randint (low = 1, high = 20, size =3)\n",
        "\n",
        "data_2 = pd.DataFrame ({\"a\": data_a,\"b\" : data_b,\"c\" : data_c})\n",
        "data_2 = data_2.T\n",
        "print(data_2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0   1   2\n",
            "a   4   9  14\n",
            "b   8  16   7\n",
            "c  18  16  19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vxAa5FMRSjC",
        "outputId": "d93d9e2d-fa49-4d28-8bf0-e3a8b9851353"
      },
      "source": [
        "#Compute a second smilarity matrix\n",
        "from sklearn.metrics import pairwise_distances #for distance matrix\n",
        "from scipy.spatial.distance import cosine #for cosine similarity\n",
        "\n",
        "dist_matrix_2 = 1-pairwise_distances(data_2, metric=\"cosine\")\n",
        "distance_matrix_2 = pd.DataFrame (dist_matrix_2)\n",
        "print(distance_matrix_2, \"RDM 2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0         1         2\n",
            "0  1.000000  0.833304  0.917949\n",
            "1  0.833304  1.000000  0.904522\n",
            "2  0.917949  0.904522  1.000000 RDM 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2R_TurLRg5T",
        "outputId": "4f43bf41-04f0-4aa7-ed21-71aa9588d9cd"
      },
      "source": [
        "#normalize matrix?? #I shoudl keep all in list of lists and then do a for loop?\n",
        "#change it to numpyy\n",
        "np_distance_matrix_1 = distance_matrix_1.to_numpy ()\n",
        "np_distance_matrix_2 = distance_matrix_2.to_numpy()\n",
        "RDM1_norm = np.linalg.norm (np_distance_matrix_1, axis = 0) #thats row wise but I'm not sure baout it, also the data is already form norla distribution and between 0 and 1 so why is it necessary?\n",
        "RDM2_norm = np.linalg.norm (np_distance_matrix_2, axis = 0)\n",
        "print(RDM1_norm, RDM2_norm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.22062499 1.19346856 1.25770547] [1.59280436 1.58510449 1.63119287]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYhZQ7babdTm",
        "outputId": "cdbe8947-9337-453f-9509-400d526b0da6"
      },
      "source": [
        "#Compare Matrices WRONGGGG\n",
        "RSA= np.dot (np_distance_matrix_1, np_distance_matrix_2)\n",
        "print(RSA)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.81749791  0.72640602  0.71780143]\n",
            " [ 0.77464339  0.88019574  0.77071991]\n",
            " [-0.07436409 -0.07764373  0.01818578]]\n",
            "4.4961156069303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isPofaxBQdLd"
      },
      "source": [
        "Samira's code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3NyF_dEQbJI"
      },
      "source": [
        "\n",
        "def compute_dist_of_dists(x, C, labels):\n",
        "  keys = np.asarray(list(x.keys()))\n",
        "  klz = np.zeros((len(keys), len(keys)))\n",
        "  prz = np.zeros((len(keys), len(keys)))\n",
        "  mean_p_value = np.zeros((len(keys), len(keys)))\n",
        "  for i in np.arange(len(keys)):\n",
        "    for j in np.arange(len(keys)):\n",
        "      klz[i][j] = np.sum(sp.stats.entropy(C[keys[i]], C[keys[j]], base=None))\n",
        "      pz = []\n",
        "      p_values = []\n",
        "      for a,b in zip(C[keys[i]], C[keys[j]]):\n",
        "        p, p_value = sp.stats.pearsonr(a,b)\n",
        "        pz.append(p)\n",
        "        p_values.append(p_value)\n",
        "\n",
        "      prz[i][j] = np.mean(pz)\n",
        "      mean_p_value[i][j] = np.mean(p_values)\n",
        "\n",
        "  return klz, prz, labels, mean_p_value\n",
        "\n",
        "def compute_dist_of_dists_over_time(x, C, labels):\n",
        "  \"\"\"\n",
        "  :param x:\n",
        "  :param C: pair wise distances of xs\n",
        "  :param labels: e.g. tokens of the story\n",
        "  :return:\n",
        "  \"\"\"\n",
        "  keys = np.asarray(list(x.keys()))\n",
        "  klz = np.zeros((len(keys), len(labels)))\n",
        "  prz = np.zeros((len(keys), len(labels)))\n",
        "  for i in np.arange(len(keys)):\n",
        "    for j in np.arange(len(keys)):\n",
        "\n",
        "      klz[i][j] = np.sum(sp.stats.entropy(C[keys[i]], C[keys[j]], base=None))\n",
        "      pz = []\n",
        "      for a,b in zip(C[keys[i]], C[keys[j]]):\n",
        "        p, _ = sp.stats.pearsonr(a,b)\n",
        "        pz.append(p)\n",
        "\n",
        "      prz[i][j] = np.mean(pz)\n",
        "\n",
        "  return klz, prz, labels\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(pad_lists([['a','b'],['c']], ''))\n",
        "    print(concat_lists([['a', 'b'], ['c']]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}